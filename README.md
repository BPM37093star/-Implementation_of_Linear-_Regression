Practical 1: Linear Regression (Ridge, Lasso) Implementation
Overview
This project implements linear regression models using Python. The goal is to understand and apply the least squares method to build linear models from scratch, and then extend these with polynomial basis expansion and regularization techniques (Ridge and Lasso) using scikit-learn. The project also involves analyzing learning curves to diagnose underfitting or overfitting, and optionally using k-fold cross-validation to optimize hyperparameters.

The project uses real-world datasets including the Wine Quality dataset.

Features
Implementation of linear regression from scratch using NumPy

Polynomial basis expansion for modeling non-linear relationships

Ridge and Lasso regression using scikit-learn

Learning curve visualization for model diagnosis

Hyperparameter tuning with k-fold cross-validation (optional)

Data preprocessing and exploratory data analysis

Dataset
Wine Quality datasets (red and white wine) from UCI Machine Learning Repository:
https://archive.ics.uci.edu/ml/datasets/Wine+Quality

California Housing dataset for initial testing
